{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common libraries\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import helper \n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# machine learning libraries    \n",
    "\n",
    "# preprocessing libraries, split data, gid search configuration, cross validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "# linear classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier   \n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import pydotplus    \n",
    "from IPython.display import Image\n",
    "from six import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe prior to modeling: (1269, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_oxycodone_0</th>\n",
       "      <th>test_cocaine_0</th>\n",
       "      <th>test_methamphetamine_0</th>\n",
       "      <th>test_opiate300_0</th>\n",
       "      <th>test_oxycodone_1</th>\n",
       "      <th>test_cocaine_1</th>\n",
       "      <th>test_methamphetamine_1</th>\n",
       "      <th>test_opiate300_1</th>\n",
       "      <th>test_oxycodone_2</th>\n",
       "      <th>test_cocaine_2</th>\n",
       "      <th>...</th>\n",
       "      <th>medication</th>\n",
       "      <th>cows_predose</th>\n",
       "      <th>cows_postdose</th>\n",
       "      <th>rbs_sexual_activity</th>\n",
       "      <th>rbs_cocaine</th>\n",
       "      <th>rbs_heroine</th>\n",
       "      <th>rbs_amphetamines</th>\n",
       "      <th>rbs_other_opiates</th>\n",
       "      <th>gender</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1269 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_oxycodone_0  test_cocaine_0  test_methamphetamine_0  \\\n",
       "0                  0.0             0.0                     0.0   \n",
       "1                  0.0             0.0                     0.0   \n",
       "2                  0.0             1.0                     0.0   \n",
       "3                  0.0             1.0                     0.0   \n",
       "4                  1.0             0.0                     0.0   \n",
       "...                ...             ...                     ...   \n",
       "1264               1.0             0.0                     0.0   \n",
       "1265               0.0             1.0                     0.0   \n",
       "1266               0.0             0.0                     0.0   \n",
       "1267               0.0             0.0                     1.0   \n",
       "1268               0.0             0.0                     0.0   \n",
       "\n",
       "      test_opiate300_0  test_oxycodone_1  test_cocaine_1  \\\n",
       "0                  1.0               0.0             0.0   \n",
       "1                  1.0               0.0             0.0   \n",
       "2                  1.0               0.0             1.0   \n",
       "3                  1.0               0.0             1.0   \n",
       "4                  1.0               1.0             1.0   \n",
       "...                ...               ...             ...   \n",
       "1264               1.0               1.0             1.0   \n",
       "1265               1.0               1.0             1.0   \n",
       "1266               1.0               1.0             1.0   \n",
       "1267               1.0               1.0             1.0   \n",
       "1268               1.0               1.0             1.0   \n",
       "\n",
       "      test_methamphetamine_1  test_opiate300_1  test_oxycodone_2  \\\n",
       "0                        0.0               0.0               0.0   \n",
       "1                        0.0               1.0               1.0   \n",
       "2                        0.0               1.0               0.0   \n",
       "3                        0.0               1.0               0.0   \n",
       "4                        1.0               1.0               1.0   \n",
       "...                      ...               ...               ...   \n",
       "1264                     1.0               1.0               1.0   \n",
       "1265                     1.0               1.0               1.0   \n",
       "1266                     1.0               1.0               1.0   \n",
       "1267                     1.0               1.0               1.0   \n",
       "1268                     1.0               1.0               1.0   \n",
       "\n",
       "      test_cocaine_2  ...  medication  cows_predose  cows_postdose  \\\n",
       "0                0.0  ...         0.0            11              6   \n",
       "1                0.0  ...         0.0             8              1   \n",
       "2                1.0  ...         1.0             8              5   \n",
       "3                1.0  ...         0.0            11              9   \n",
       "4                1.0  ...         0.0            11              6   \n",
       "...              ...  ...         ...           ...            ...   \n",
       "1264             1.0  ...         0.0            11              8   \n",
       "1265             1.0  ...         0.0            26             10   \n",
       "1266             1.0  ...         0.0            14              6   \n",
       "1267             1.0  ...         1.0            12              5   \n",
       "1268             1.0  ...         0.0            16              6   \n",
       "\n",
       "      rbs_sexual_activity  rbs_cocaine  rbs_heroine  rbs_amphetamines  \\\n",
       "0                     1.0          0.0         30.0               0.0   \n",
       "1                     1.0          0.0         30.0               0.0   \n",
       "2                     1.0         23.0         30.0               0.0   \n",
       "3                     1.0          2.0         30.0               0.0   \n",
       "4                     1.0          0.0          4.0               0.0   \n",
       "...                   ...          ...          ...               ...   \n",
       "1264                  1.0          2.0         30.0               0.0   \n",
       "1265                  1.0         13.0         30.0               0.0   \n",
       "1266                  1.0          0.0         30.0               0.0   \n",
       "1267                  0.0          0.0          0.0               0.0   \n",
       "1268                  1.0          0.0         30.0               0.0   \n",
       "\n",
       "      rbs_other_opiates  gender  dropout  \n",
       "0                   0.0     1.0      0.0  \n",
       "1                   0.0     1.0      0.0  \n",
       "2                   0.0     1.0      0.0  \n",
       "3                   1.0     2.0      0.0  \n",
       "4                  26.0     2.0      1.0  \n",
       "...                 ...     ...      ...  \n",
       "1264                0.0     2.0      1.0  \n",
       "1265                4.0     1.0      1.0  \n",
       "1266                0.0     2.0      1.0  \n",
       "1267                0.0     2.0      1.0  \n",
       "1268                0.0     1.0      1.0  \n",
       "\n",
       "[1269 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read csv file\n",
    "data = pd.read_csv('../data/38_features.csv')\n",
    "\n",
    "print('Shape of dataframe prior to modeling:', data.shape)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_oxycodone_0',\n",
       " 'test_cocaine_0',\n",
       " 'test_methamphetamine_0',\n",
       " 'test_opiate300_0',\n",
       " 'test_oxycodone_1',\n",
       " 'test_cocaine_1',\n",
       " 'test_methamphetamine_1',\n",
       " 'test_opiate300_1',\n",
       " 'test_oxycodone_2',\n",
       " 'test_cocaine_2',\n",
       " 'test_methamphetamine_2',\n",
       " 'test_opiate300_2',\n",
       " 'test_oxycodone_3',\n",
       " 'test_cocaine_3',\n",
       " 'test_methamphetamine_3',\n",
       " 'test_opiate300_3',\n",
       " 'test_oxycodone_4',\n",
       " 'test_cocaine_4',\n",
       " 'test_methamphetamine_4',\n",
       " 'test_opiate300_4',\n",
       " 'survey_cocaine_0',\n",
       " 'survey_oxycodone_0',\n",
       " 'survey_methamphetamine_0',\n",
       " 'survey_opiates_0',\n",
       " 'survey_cocaine_4',\n",
       " 'survey_oxycodone_4',\n",
       " 'survey_methamphetamine_4',\n",
       " 'survey_opiates_4',\n",
       " 'medication',\n",
       " 'cows_predose',\n",
       " 'cows_postdose',\n",
       " 'rbs_sexual_activity',\n",
       " 'rbs_cocaine',\n",
       " 'rbs_heroine',\n",
       " 'rbs_amphetamines',\n",
       " 'rbs_other_opiates',\n",
       " 'gender',\n",
       " 'dropout']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data to Dev and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (916, 37)\n",
      "Shape of X_val: (175, 37)\n",
      "Shape of X_test: (178, 37)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# assign variables\n",
    "X, y = data.drop(columns='dropout'), data['dropout']\n",
    "\n",
    "# create the dev and test sets \n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.14, random_state=42)\n",
    "\n",
    "# create the train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.16, random_state=42)\n",
    "\n",
    "# check the shape of the train, validation, and test sets\n",
    "print('Shape of X_train:', X_train.shape)\n",
    "print('Shape of X_val:', X_val.shape)\n",
    "print('Shape of X_test:', X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Patient Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_oxycodone_0             0.0\n",
       "test_cocaine_0               0.0\n",
       "test_methamphetamine_0       0.0\n",
       "test_opiate300_0             1.0\n",
       "test_oxycodone_1             0.0\n",
       "test_cocaine_1               0.0\n",
       "test_methamphetamine_1       0.0\n",
       "test_opiate300_1             0.0\n",
       "test_oxycodone_2             0.0\n",
       "test_cocaine_2               0.0\n",
       "test_methamphetamine_2       0.0\n",
       "test_opiate300_2             0.0\n",
       "test_oxycodone_3             0.0\n",
       "test_cocaine_3               0.0\n",
       "test_methamphetamine_3       0.0\n",
       "test_opiate300_3             0.0\n",
       "test_oxycodone_4             0.0\n",
       "test_cocaine_4               0.0\n",
       "test_methamphetamine_4       0.0\n",
       "test_opiate300_4             0.0\n",
       "survey_cocaine_0             0.0\n",
       "survey_oxycodone_0           0.0\n",
       "survey_methamphetamine_0     0.0\n",
       "survey_opiates_0            20.0\n",
       "survey_cocaine_4             0.0\n",
       "survey_oxycodone_4           0.0\n",
       "survey_methamphetamine_4     0.0\n",
       "survey_opiates_4             0.0\n",
       "medication                   0.0\n",
       "cows_predose                11.0\n",
       "cows_postdose                3.0\n",
       "rbs_sexual_activity          1.0\n",
       "rbs_cocaine                  0.0\n",
       "rbs_heroine                 20.0\n",
       "rbs_amphetamines             0.0\n",
       "rbs_other_opiates            0.0\n",
       "gender                       1.0\n",
       "Name: 960, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.iloc[215, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import column transformer, standard scaler, one hot encoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def preprocess_data(train_df, val_df, test_df, numeric_features, categorical_features):\n",
    "    # Define the column transformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Fit the preprocessor on the training data\n",
    "    preprocessor.fit(train_df)\n",
    "    \n",
    "    # Transform the training, validation, and test data\n",
    "    X_train = preprocessor.transform(train_df)\n",
    "    X_val = preprocessor.transform(val_df)\n",
    "    X_test = preprocessor.transform(test_df)\n",
    "    \n",
    "    return X_train, X_val, X_test, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric features\n",
    "numeric_features = [col for col in X_train.columns if X_train[col].dtype != 'object']\n",
    "categorical_features = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# preprocess the data\n",
    "X_train, X_val, X_test, pipeline = preprocess_data(X_train, X_val, X_test, numeric_features, categorical_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Grid Search\n",
    "We will create a reusable function to perform grid search with any classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom grid search function\n",
    "def perform_grid_search(X_train, y_train, X_val, y_val, classifier, hyperparams):\n",
    "    \"\"\"\n",
    "    Perform grid search with cross-validation for a given classifier and hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train: Training features dataframe.\n",
    "    - y_train: Training target series.\n",
    "    - X_val: Validation features dataframe.\n",
    "    - y_val: Validation target series.\n",
    "    - classifier: The classifier to use (e.g., XGBClassifier()).\n",
    "    - hyperparams: Dictionary of hyperparameters to search.\n",
    "\n",
    "    Returns:\n",
    "    - results_df: Pandas DataFrame containing the results of the grid search.\n",
    "    \"\"\"\n",
    "    # Define a custom scoring function for the C-index\n",
    "    def cindex_score(y_true, y_pred):\n",
    "        return helper.cindex(y_true, y_pred)\n",
    "\n",
    "    # Wrap the custom scoring function using make_scorer\n",
    "    cindex_scorer = make_scorer(cindex_score, greater_is_better=True)\n",
    "\n",
    "    # Set up GridSearchCV with cross-validation and custom scorer\n",
    "    grid_search = GridSearchCV(estimator=classifier, param_grid=hyperparams, cv=5, scoring=cindex_scorer, n_jobs=-1, verbose=1)\n",
    "\n",
    "    # Fit GridSearchCV to the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Retrieve the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    # Retrieve the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Get the probability scores from the best model\n",
    "    y_val_preds = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Calculate the C-index on the validation set\n",
    "    c_index = helper.cindex(y_val.values, y_val_preds)\n",
    "    \n",
    "    # Store the results in a DataFrame\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Param Grid and loop through pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classifiers and hyperparameters\n",
    "\n",
    "classifiers = {\n",
    "    'Logistic Regression': (LogisticRegression(), {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    }),\n",
    "    'Random Forest': (RandomForestClassifier(), {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    'XGBoost': (XGBClassifier(), {\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    })\n",
    "}\n",
    "\n",
    "# store results in a dictionary\n",
    "results = {}\n",
    "\n",
    "# Perform grid search for each classifier\n",
    "for clf_name, (clf, params) in classifiers.items():\n",
    "    print(f\"Running grid search for {clf_name}...\")\n",
    "    results[clf_name] = perform_grid_search(X_train, y_train, X_val, y_val, clf, params)\n",
    "    print()\n",
    "\n",
    "\n",
    "# print the best results for each classifier\n",
    "for clf_name, _ in classifiers.items():\n",
    "    best_cindex = results[clf_name]['mean_test_score'].max()\n",
    "    best_params = results[clf_name]['params'][results[clf_name]['mean_test_score'].idxmax()]\n",
    "    print(f\"Best C-index for {clf_name}: {best_cindex:.4f}\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run each classifier with the best params on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run each classifier with the best params on the test set\n",
    "for clf_name, (clf, params) in classifiers.items():\n",
    "    # Initialize the classifier\n",
    "    clf.set_params(**results[clf_name].loc[results[clf_name]['rank_test_score'] == 1, 'params'].iloc[0])\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the probability scores\n",
    "    y_test_preds = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate the C-index\n",
    "    c_index = helper.cindex(y_test.values, y_test_preds)\n",
    "    print(f\"{clf_name} C-index for Test Set: {c_index:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix with Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Assuming y_test contains the true labels and y_test_preds contains the predicted labels\n",
    "for clf_name, (clf, params) in classifiers.items():\n",
    "    # Initialize the classifier\n",
    "    clf.set_params(**results[clf_name].loc[results[clf_name]['rank_test_score'] == 1, 'params'].iloc[0])\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the predicted labels\n",
    "    y_test_preds = clf.predict(X_test)\n",
    "\n",
    "    # calculate recall\n",
    "    recall = recall_score(y_test, y_test_preds, pos_label=1.0)  # Adjust pos_label as needed\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_test_preds, pos_label=1.0)  # Adjust pos_label as needed\n",
    "    \n",
    "    # Plot the precision right before each confusion matrix\n",
    "    print(f'{clf_name} Precision Score: {precision:.2f}')\n",
    "    print(f'{clf_name} Recall Score: {recall:.2f}')\n",
    "    print()\n",
    "\n",
    "    # plot confusion matrix\n",
    "    helper.plot_confusion_matrix(y_test, y_test_preds, classes=['No Dropout', 'Dropout'],\n",
    "                          title=f'{clf_name} - Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create classifier object\n",
    "xgb = (\n",
    "        classifiers['XGBoost'][0]\n",
    "        .set_params(**results['XGBoost']\n",
    "        .loc[results['XGBoost']['rank_test_score'] == 1, 'params']\n",
    "        .iloc[0])\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_feature_importance(xgb, pipeline, X_train, metric=\"gain\", num_features=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming 'data' is a DataFrame and 'dropout' is the target variable\n",
    "X = data[['survey_opiates_0', 'cows_postdose']]\n",
    "y = data['dropout']\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the range for the grid\n",
    "x_min, x_max = X['survey_opiates_0'].min() - 1, X['survey_opiates_0'].max() + 1\n",
    "y_min, y_max = X['cows_postdose'].min() - 1, X['cows_postdose'].max() + 1\n",
    "\n",
    "# Create a mesh grid\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the grid to pass it to the model\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Predict the class for each point in the grid\n",
    "Z = model.predict(grid)\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='survey_opiates_0', y='cows_postdose', hue='dropout', data=data)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "\n",
    "# Plot the decision boundary line\n",
    "plt.contour(xx, yy, Z, levels=[0.5], colors='black', linestyles='--')\n",
    "\n",
    "plt.title('Self Reported Use Week 4, Previous 30 days heroine use')\n",
    "plt.xlabel('survey_opiates_4')\n",
    "plt.ylabel('rbs_heroine')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming 'data' is a DataFrame and 'dropout' is the target variable\n",
    "X = data[['survey_opiates_0', 'cows_postdose']]\n",
    "y = data['dropout']\n",
    "\n",
    "# Create a pipeline with standard scaling and XGBoost\n",
    "model = make_pipeline(StandardScaler(), xgb.XGBClassifier())\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the range for the grid\n",
    "x_min, x_max = X['survey_opiates_0'].min() - 1, X['survey_opiates_0'].max() + 1\n",
    "y_min, y_max = X['cows_postdose'].min() - 1, X['cows_postdose'].max() + 1\n",
    "\n",
    "# Create a mesh grid\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the grid to pass it to the model\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Predict the class for each point in the grid\n",
    "Z = model.predict(grid)\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='survey_opiates_0', y='cows_postdose', hue='dropout', data=data)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "\n",
    "# Plot the decision boundary line\n",
    "plt.contour(xx, yy, Z, levels=[0.5], colors='black', linestyles='--')\n",
    "\n",
    "plt.title('Withdrawal syndrome scale, medication dose and dropout')\n",
    "plt.xlabel('meds_methadone_0')\n",
    "plt.ylabel('cows_postdose')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have the accuracies stored in the following dictionaries\n",
    "accuracies = {\n",
    "    'Logistic Regression': {\n",
    "        'train': 0.85,\n",
    "        'val': 0.80,\n",
    "        'test': 0.78\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'train': 0.90,\n",
    "        'val': 0.82,\n",
    "        'test': 0.80\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'train': 0.88,\n",
    "        'val': 0.83,\n",
    "        'test': 0.81\n",
    "    }\n",
    "}\n",
    "\n",
    "# Extract the data\n",
    "models = list(accuracies.keys())\n",
    "train_accuracies = [accuracies[model]['train'] for model in models]\n",
    "val_accuracies = [accuracies[model]['val'] for model in models]\n",
    "test_accuracies = [accuracies[model]['test'] for model in models]\n",
    "\n",
    "# Set up the bar plot\n",
    "x = np.arange(len(models))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "rects1 = ax.bar(x - width, train_accuracies, width, label='Train')\n",
    "rects2 = ax.bar(x, val_accuracies, width, label='Validation')\n",
    "rects3 = ax.bar(x + width, test_accuracies, width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy by model and dataset')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend()\n",
    "# put legend outside of plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Attach a text label above each bar in rects, displaying its height.\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
